{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "- https://www.tensorflow.org/tutorials/generative/autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_features = pd.read_csv('handout/pretrain_features.csv')\n",
    "pretrain_labels = pd.read_csv('handout/pretrain_labels.csv')\n",
    "train_features = pd.read_csv('handout/train_features.csv')\n",
    "train_labels = pd.read_csv('handout/train_labels.csv')\n",
    "test_features = pd.read_csv('handout/test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pretrain_features.columns[2:]:\n",
    "    if len(pretrain_features[c].unique()) < 2:\n",
    "        pretrain_features = pretrain_features.drop(c, axis=1)\n",
    "        train_features = train_features.drop(c, axis=1)\n",
    "        test_features = test_features.drop(c, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            Input(shape=(input_dim,)),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(latent_dim),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            Input(shape=(latent_dim,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(input_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain_train, X_pretrain_val, y_pretrain_train, y_pretrain_val = train_test_split(\n",
    "    pretrain_features[pretrain_features.columns[2:]], pretrain_labels[[\"lumo_energy\"]], test_size=0.01, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(X_pretrain_train.shape[1], latent_dim=32)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 15:53:02.414199: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 385704000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1547/1547 [==============================] - 5s 3ms/step - loss: 0.0220 - val_loss: 0.0137\n",
      "Epoch 2/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 3/20\n",
      "1547/1547 [==============================] - 4s 3ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 4/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 5/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 6/20\n",
      "1547/1547 [==============================] - 4s 3ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 7/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 8/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 9/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 10/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 11/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 12/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 13/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 14/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 15/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 16/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 17/20\n",
      "1547/1547 [==============================] - 4s 3ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 18/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 19/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 20/20\n",
      "1547/1547 [==============================] - 4s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_pretrain_train, X_pretrain_train, epochs=20, batch_size=32, validation_data=(X_pretrain_val, X_pretrain_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELumon(Model):\n",
    "    def __init__(self, autoencoder):\n",
    "        super(ELumon, self).__init__()\n",
    "        self.encoder = autoencoder.encoder\n",
    "        self.regressor = tf.keras.Sequential([\n",
    "            Input(shape=self.encoder.output_shape[1:]),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(1, activation='linear', kernel_regularizer=\"l2\")\n",
    "        ])\n",
    "        # Set all layers to trainable\n",
    "        for layer in self.encoder.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.regressor(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "elumon = ELumon(autoencoder)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "elumon.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain_train, X_pretrain_val, y_pretrain_train, y_pretrain_val = train_test_split(\n",
    "    pretrain_features[pretrain_features.columns[2:]], pretrain_labels[[\"lumo_energy\"]], test_size=0.15, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 9.4297 - val_loss: 2.8839\n",
      "Epoch 2/20\n",
      "1329/1329 [==============================] - 2s 2ms/step - loss: 1.8230 - val_loss: 0.1095\n",
      "Epoch 3/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.1880 - val_loss: 0.1137\n",
      "Epoch 4/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.1386 - val_loss: 0.0855\n",
      "Epoch 5/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.1110 - val_loss: 0.0763\n",
      "Epoch 6/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0920 - val_loss: 0.0714\n",
      "Epoch 7/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0803 - val_loss: 0.0664\n",
      "Epoch 8/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0737 - val_loss: 0.0634\n",
      "Epoch 9/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0678 - val_loss: 0.0590\n",
      "Epoch 10/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0643 - val_loss: 0.0560\n",
      "Epoch 11/20\n",
      "1329/1329 [==============================] - 2s 2ms/step - loss: 0.0597 - val_loss: 0.0518\n",
      "Epoch 12/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0556 - val_loss: 0.0497\n",
      "Epoch 13/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0523 - val_loss: 0.0517\n",
      "Epoch 14/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0494 - val_loss: 0.0441\n",
      "Epoch 15/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0472 - val_loss: 0.0409\n",
      "Epoch 16/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0443 - val_loss: 0.0443\n",
      "Epoch 17/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0416 - val_loss: 0.0386\n",
      "Epoch 18/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0400 - val_loss: 0.0349\n",
      "Epoch 19/20\n",
      "1329/1329 [==============================] - 3s 2ms/step - loss: 0.0375 - val_loss: 0.0340\n",
      "Epoch 20/20\n",
      "1329/1329 [==============================] - 2s 2ms/step - loss: 0.0358 - val_loss: 0.0324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f48a76d2640>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elumon.fit(X_pretrain_train, y_pretrain_train, epochs=20, batch_size=32, validation_data=(X_pretrain_val, y_pretrain_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGap(Model):\n",
    "    def __init__(self, premodel):\n",
    "        super(EGap, self).__init__()\n",
    "        self.encoder = premodel.encoder\n",
    "        self.regressor = tf.keras.Sequential([\n",
    "            Input(shape=self.encoder.output_shape[1:]),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(8, activation='relu'),\n",
    "            layers.Dense(1, activation='linear', kernel_regularizer=\"l2\")\n",
    "        ])\n",
    "        # Set all layers to trainable\n",
    "        for layer in self.encoder.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.regressor(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "egap = EGap(elumon)\n",
    "egap.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(\n",
    "    train_features[train_features.columns[2:]], train_labels[[\"homo_lumo_gap\"]], test_size=0.02, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 1.6336 - val_loss: 3.3093\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.5729 - val_loss: 3.2944\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4649 - val_loss: 3.1854\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3731 - val_loss: 3.1214\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3163 - val_loss: 3.0642\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2247 - val_loss: 3.0033\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1620 - val_loss: 3.0210\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1203 - val_loss: 3.0473\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0870 - val_loss: 2.9725\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9807 - val_loss: 2.9076\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0043 - val_loss: 2.9344\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9745 - val_loss: 2.9412\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9713 - val_loss: 2.9640\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9360 - val_loss: 2.9531\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8857 - val_loss: 2.9474\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9164 - val_loss: 2.9519\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8999 - val_loss: 2.9282\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8989 - val_loss: 2.9919\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8790 - val_loss: 3.0099\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8108 - val_loss: 3.0179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f48a7508520>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egap.fit(X_train_train, y_train_train, epochs=20, batch_size=90, validation_data=(X_train_val, y_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = egap.predict(test_features[test_features.columns[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({\"Id\": test_features[\"Id\"], \"y\": y_pred.reshape(-1,)})\n",
    "output_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4101d65f246ca3c6545fd876c414d4a4b9c372f5e6e13942927864f36a2ffe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML-projects')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
