{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:28:34.314010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "- https://www.tensorflow.org/tutorials/generative/autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_features = pd.read_csv('handout/pretrain_features.csv')\n",
    "pretrain_labels = pd.read_csv('handout/pretrain_labels.csv')\n",
    "train_features = pd.read_csv('handout/train_features.csv')\n",
    "train_labels = pd.read_csv('handout/train_labels.csv')\n",
    "test_features = pd.read_csv('handout/test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pretrain_features.columns[2:]:\n",
    "    if len(pretrain_features[c].unique()) < 2:\n",
    "        pretrain_features = pretrain_features.drop(c, axis=1)\n",
    "        train_features = train_features.drop(c, axis=1)\n",
    "        test_features = test_features.drop(c, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            Input(shape=(input_dim,)),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(latent_dim),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            Input(shape=(latent_dim,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(input_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain_train, X_pretrain_val, y_pretrain_train, y_pretrain_val = train_test_split(\n",
    "    pretrain_features[pretrain_features.columns[2:]], pretrain_labels[[\"lumo_energy\"]], test_size=0.1, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:29:06.186506: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-12 14:29:06.187907: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-12 14:29:06.187944: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-12 14:29:06.187988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (t3ui01.psi.ch): /proc/driver/nvidia/version does not exist\n",
      "2022-05-12 14:29:06.188590: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-12 14:29:06.195135: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(X_pretrain_train.shape[1], latent_dim=32)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:29:13.187379: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-12 14:29:13.187949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294660000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0224 - val_loss: 0.0141\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0090 - val_loss: 0.0090\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_pretrain_train, X_pretrain_train, epochs=10, batch_size=32, validation_data=(X_pretrain_val, X_pretrain_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELumon(Model):\n",
    "    def __init__(self, autoencoder):\n",
    "        super(ELumon, self).__init__()\n",
    "        self.encoder = autoencoder.encoder\n",
    "        self.regressor = tf.keras.Sequential([\n",
    "            Input(shape=self.encoder.output_shape[1:]),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(1, activation='linear', kernel_regularizer=\"l2\")\n",
    "        ])\n",
    "        # Set all layers to trainable\n",
    "        for layer in self.encoder.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.regressor(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "elumon = ELumon(autoencoder)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "elumon.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "45/45 [==============================] - 1s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f40402a10a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elumon.fit(X_pretrain_train, y_pretrain_train, epochs=2, batch_size=1000, validation_data=(X_pretrain_val, y_pretrain_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = elumon.predict(X_pretrain_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7697188e-08],\n",
       "       [2.7368214e-08]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4101d65f246ca3c6545fd876c414d4a4b9c372f5e6e13942927864f36a2ffe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML-projects')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
