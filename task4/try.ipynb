{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 17:36:43.131348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "- https://www.tensorflow.org/tutorials/generative/autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_features = pd.read_csv('handout/pretrain_features.csv')\n",
    "pretrain_labels = pd.read_csv('handout/pretrain_labels.csv')\n",
    "train_features = pd.read_csv('handout/train_features.csv')\n",
    "train_labels = pd.read_csv('handout/train_labels.csv')\n",
    "test_features = pd.read_csv('handout/test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pretrain_features.columns[2:]:\n",
    "    if len(pretrain_features[c].unique()) < 2:\n",
    "        pretrain_features = pretrain_features.drop(c, axis=1)\n",
    "        train_features = train_features.drop(c, axis=1)\n",
    "        test_features = test_features.drop(c, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            Input(shape=(input_dim,)),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(latent_dim),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            Input(shape=(latent_dim,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(input_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain_train, X_pretrain_val, y_pretrain_train, y_pretrain_val = train_test_split(\n",
    "    pretrain_features[pretrain_features.columns[2:]], pretrain_labels[[\"lumo_energy\"]], test_size=0.001, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 17:38:08.374172: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-12 17:38:08.375872: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-12 17:38:08.375917: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-12 17:38:08.375962: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (t3ui01.psi.ch): /proc/driver/nvidia/version does not exist\n",
      "2022-05-12 17:38:08.376592: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-12 17:38:08.384635: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(X_pretrain_train.shape[1], latent_dim=32)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 17:38:14.790034: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 389210400 exceeds 10% of free system memory.\n",
      "2022-05-12 17:38:15.387400: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 389210400 exceeds 10% of free system memory.\n",
      "2022-05-12 17:38:15.790100: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-12 17:38:15.790657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294660000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1561/1561 [==============================] - 5s 3ms/step - loss: 0.0219 - val_loss: 0.0145\n",
      "Epoch 2/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 3/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 4/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 5/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 6/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 7/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 8/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 9/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 10/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 11/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0086 - val_loss: 0.0090\n",
      "Epoch 12/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 13/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 14/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 15/15\n",
      "1561/1561 [==============================] - 4s 2ms/step - loss: 0.0081 - val_loss: 0.0085\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_pretrain_train, X_pretrain_train, epochs=15, batch_size=32, validation_data=(X_pretrain_val, X_pretrain_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELumon(Model):\n",
    "    def __init__(self, autoencoder):\n",
    "        super(ELumon, self).__init__()\n",
    "        self.encoder = autoencoder.encoder\n",
    "        self.regressor = tf.keras.Sequential([\n",
    "            Input(shape=self.encoder.output_shape[1:]),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(8, activation='relu'),\n",
    "        ])\n",
    "        self.top = tf.keras.Sequential([\n",
    "            Input(shape=self.regressor.output_shape[1:]),\n",
    "            layers.Dense(1, activation='linear', kernel_regularizer=\"l2\")\n",
    "        ])\n",
    "        # Set all layers to trainable\n",
    "        for layer in self.encoder.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        reg = self.regressor(encoded)\n",
    "        return self.top(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elumon = ELumon(autoencoder)\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "elumon.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain_train, X_pretrain_val, y_pretrain_train, y_pretrain_val = train_test_split(\n",
    "    pretrain_features[pretrain_features.columns[2:]], pretrain_labels[[\"lumo_energy\"]], test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.8026 - val_loss: 0.0755\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0492 - val_loss: 0.0424\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0295 - val_loss: 0.0270\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0224 - val_loss: 0.0147\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0170 - val_loss: 0.0239\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0073 - val_loss: 0.0085\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0026 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "history_elumon = elumon.fit(X_pretrain_train, y_pretrain_train, epochs=20, batch_size=32, validation_data=(X_pretrain_val, y_pretrain_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGap(Model):\n",
    "    def __init__(self, premodel):\n",
    "        super(EGap, self).__init__()\n",
    "        self.encoder = premodel.encoder\n",
    "        self.regressor = premodel.regressor\n",
    "        self.top = tf.keras.Sequential([\n",
    "            Input(shape=self.regressor.output_shape[1:]),\n",
    "            layers.Dense(2, activation='relu'),\n",
    "            layers.Dense(1, activation='linear', kernel_regularizer=\"l2\")\n",
    "        ])\n",
    "\n",
    "        for layer in self.encoder.layers:\n",
    "            layer.trainable = False\n",
    "        for layer in self.regressor.layers:\n",
    "            layer.trainable = True\n",
    "        for layer in self.top.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        reg = self.regressor(encoded)\n",
    "        return self.top(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "egap = EGap(elumon)\n",
    "egap.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(\n",
    "    train_features[train_features.columns[2:]], train_labels[[\"homo_lumo_gap\"]], test_size=0.02, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4/4 [==============================] - 1s 46ms/step - loss: 7.3649 - val_loss: 3.4781\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.8656 - val_loss: 2.6927\n",
      "Epoch 3/15\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.6827 - val_loss: 2.0551\n",
      "Epoch 4/15\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.0420 - val_loss: 1.5378\n",
      "Epoch 5/15\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8444 - val_loss: 1.1042\n",
      "Epoch 6/15\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0763 - val_loss: 0.7583\n",
      "Epoch 7/15\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6588 - val_loss: 0.4983\n",
      "Epoch 8/15\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.3829 - val_loss: 0.3185\n",
      "Epoch 9/15\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0431 - val_loss: 0.1949\n",
      "Epoch 10/15\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8239 - val_loss: 0.1187\n",
      "Epoch 11/15\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6285 - val_loss: 0.0726\n",
      "Epoch 12/15\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5537 - val_loss: 0.0436\n",
      "Epoch 13/15\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5008 - val_loss: 0.0311\n",
      "Epoch 14/15\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4001 - val_loss: 0.0272\n",
      "Epoch 15/15\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4025 - val_loss: 0.0296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43dc70cdc0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egap.fit(X_train_train, y_train_train, epochs=15, validation_data=(X_train_val, y_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = egap.predict(test_features[test_features.columns[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({\"Id\": test_features[\"Id\"], \"y\": y_pred.reshape(-1,)})\n",
    "output_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4101d65f246ca3c6545fd876c414d4a4b9c372f5e6e13942927864f36a2ffe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML-projects')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
