{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:51:21.377311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "- https://www.tensorflow.org/tutorials/generative/autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_features = pd.read_csv('handout/pretrain_features.csv')\n",
    "pretrain_labels = pd.read_csv('handout/pretrain_labels.csv')\n",
    "train_features = pd.read_csv('handout/train_features.csv')\n",
    "train_labels = pd.read_csv('handout/train_labels.csv')\n",
    "test_features = pd.read_csv('handout/test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pretrain_features.columns[2:]:\n",
    "    if len(pretrain_features[c].unique()) < 2:\n",
    "        pretrain_features = pretrain_features.drop(c, axis=1)\n",
    "        train_features = train_features.drop(c, axis=1)\n",
    "        test_features = test_features.drop(c, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            Input(shape=(input_dim,)),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(latent_dim),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            Input(shape=(latent_dim,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(input_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain_train, X_pretrain_val, y_pretrain_train, y_pretrain_val = train_test_split(\n",
    "    pretrain_features[pretrain_features.columns[2:]], pretrain_labels[[\"lumo_energy\"]], test_size=0.1, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:51:44.839672: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-12 14:51:44.840755: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-12 14:51:44.840782: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-12 14:51:44.840818: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (t3ui01.psi.ch): /proc/driver/nvidia/version does not exist\n",
      "2022-05-12 14:51:44.841291: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-12 14:51:44.846521: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(X_pretrain_train.shape[1], latent_dim=32)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:51:46.715479: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 350640000 exceeds 10% of free system memory.\n",
      "2022-05-12 14:51:47.227424: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 350640000 exceeds 10% of free system memory.\n",
      "2022-05-12 14:51:47.497465: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-12 14:51:47.498060: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294660000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0227 - val_loss: 0.0142\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 4s 2ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0090 - val_loss: 0.0090\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_pretrain_train, X_pretrain_train, epochs=10, batch_size=32, validation_data=(X_pretrain_val, X_pretrain_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELumon(Model):\n",
    "    def __init__(self, autoencoder):\n",
    "        super(ELumon, self).__init__()\n",
    "        self.encoder = autoencoder.encoder\n",
    "        self.regressor = tf.keras.Sequential([\n",
    "            Input(shape=self.encoder.output_shape[1:]),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(1, activation='linear', kernel_regularizer=\"l2\")\n",
    "        ])\n",
    "        # Set all layers to trainable\n",
    "        for layer in self.encoder.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.regressor(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elumon = ELumon(autoencoder)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "elumon.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:52:38.118162: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 350640000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 9.3644 - val_loss: 3.2903\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 1.6524 - val_loss: 0.1166\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1276 - val_loss: 0.0821\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0937 - val_loss: 0.0761\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0800 - val_loss: 0.0675\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0734 - val_loss: 0.0638\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0684 - val_loss: 0.0592\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0636 - val_loss: 0.0557\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0530\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.0550 - val_loss: 0.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f7aac5280>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elumon.fit(X_pretrain_train, y_pretrain_train, epochs=10, batch_size=32, validation_data=(X_pretrain_val, y_pretrain_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGap(Model):\n",
    "    def __init__(self, premodel):\n",
    "        super(EGap, self).__init__()\n",
    "        self.encoder = premodel.encoder\n",
    "        self.regressor = tf.keras.Sequential([\n",
    "            Input(shape=self.encoder.output_shape[1:]),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(1, activation='linear', kernel_regularizer=\"l2\")\n",
    "        ])\n",
    "        # Set all layers to trainable\n",
    "        for layer in self.encoder.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.regressor(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "egap = EGap(elumon)\n",
    "egap.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(\n",
    "    train_features[train_features.columns[2:]], train_labels[[\"homo_lumo_gap\"]], test_size=0.02, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 54ms/step - loss: 4.7848 - val_loss: 1.8250\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.3233 - val_loss: 3.9508\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.8178 - val_loss: 6.4901\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.4682 - val_loss: 8.7711\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2948 - val_loss: 11.0489\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.1725 - val_loss: 12.8866\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.0200 - val_loss: 13.8013\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1236 - val_loss: 13.4427\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.9095 - val_loss: 12.8805\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7737 - val_loss: 12.5843\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.7421 - val_loss: 12.0098\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.8229 - val_loss: 11.3911\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5795 - val_loss: 10.2628\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.6140 - val_loss: 9.4811\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5512 - val_loss: 8.8608\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.5480 - val_loss: 8.3311\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4935 - val_loss: 7.9294\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4796 - val_loss: 7.5329\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.3701 - val_loss: 7.2190\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.3899 - val_loss: 6.8082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f34015b20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egap.fit(X_train_train, y_train_train, epochs=20, batch_size=32, validation_data=(X_train_val, y_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = egap.predict(test_features[test_features.columns[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({\"Id\": test_features[\"Id\"], \"y\": y_pred.reshape(-1,)})\n",
    "output_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4101d65f246ca3c6545fd876c414d4a4b9c372f5e6e13942927864f36a2ffe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML-projects')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
