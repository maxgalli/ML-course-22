{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt(\"handout/train_triplets.txt\", dtype=str, delimiter=\" \")\n",
    "test = np.loadtxt(\"handout/test_triplets.txt\", dtype=str, delimiter=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mpimg.imread('handout/food/00000.jpg')\n",
    "print(len(np.ndarray.flatten(img)))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm = tf.keras.utils.normalize(img, axis=1)\n",
    "plt.imshow(img_norm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "img_size = 224\n",
    "#for row in train[:2000]:\n",
    "for row in train:\n",
    "    #array = [mpimg.imread(f\"handout/food/{n}.jpg\") for n in row]\n",
    "    #array = [img_to_array(load_img(f\"handout/food/{n}.jpg\")) for n in row]\n",
    "    #array = [tf.keras.utils.normalize(cv2.imread(f\"handout/food/{n}.jpg\")) for n in row]\n",
    "    #array = [cv2.imread(f\"handout/food/{n}.jpg\") for n in row]\n",
    "    array = np.hstack([np.ndarray.flatten(cv2.resize(cv2.imread(f\"handout/food/{n}.jpg\"), (img_size, img_size))) for n in row])\n",
    "    rows.append(array)\n",
    "train_man = np.vstack(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train)%2 != 0:\n",
    "    idx = int((len(train_man) + 1) / 2)\n",
    "else:\n",
    "    idx = int(len(train_man) / 2)\n",
    "\n",
    "train_man_one = train_man[:idx]\n",
    "train_man_two = train_man[idx:]\n",
    "\n",
    "sep = img_size * img_size * 3\n",
    "t = np.copy(train_man_two[sep:2*sep])\n",
    "train_man_two[sep:2*sep] = train_man_two[2*sep:]\n",
    "train_man_two[2*sep:] = t\n",
    "\n",
    "y_labels_one = np.ones(len(train_man_one))\n",
    "y_labels_two = np.zeros(len(train_man_two))\n",
    "y_labels = np.hstack([y_labels_one, y_labels_two])\n",
    "x_train = np.vstack([train_man_one, train_man_two])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/model_{}\".format(datetime.today().strftime('%Y%m%d_%H%M%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def plot_eval(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 8))\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"training loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"validation loss\")\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"training accuracy\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"validation accuracy\")\n",
    "    ax[1].legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_eval(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed2e7aed9813acd8de509c8c2438bc56aefda22674c3c554e0205f5dbd1f21e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('intro-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
