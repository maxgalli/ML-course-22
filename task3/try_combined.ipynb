{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.applications import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename, target_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape.\n",
    "    \"\"\"\n",
    "\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, target_shape)\n",
    "    image = resnet.preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling data\n",
    "\n",
    "train = np.loadtxt(\"handout/train_triplets.txt\", dtype=str, delimiter=\" \")\n",
    "train = train[:2]\n",
    "\n",
    "anchor_images = [f\"handout/food/{number}.jpg\" for number in list(train[:, 0])]\n",
    "positive_images = [f\"handout/food/{number}.jpg\" for number in list(train[:, 1])]\n",
    "negative_images = [f\"handout/food/{number}.jpg\" for number in list(train[:, 2])]\n",
    "\n",
    "image_count = len(anchor_images)\n",
    "\n",
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n",
    "\n",
    "anchor_dataset = anchor_dataset.map(preprocess_image)\n",
    "positive_dataset = positive_dataset.map(preprocess_image)\n",
    "negative_dataset = negative_dataset.map(preprocess_image)\n",
    "\n",
    "one_anchor_dataset = anchor_dataset.take(round(.5 * image_count))\n",
    "two_anchor_dataset = anchor_dataset.skip(round(.5 * image_count))\n",
    "one_positive_dataset = positive_dataset.take(round(.5 * image_count))\n",
    "two_positive_dataset = positive_dataset.skip(round(.5 * image_count))\n",
    "one_negative_dataset = negative_dataset.take(round(.5 * image_count))\n",
    "two_negative_dataset = negative_dataset.skip(round(.5 * image_count))\n",
    "\n",
    "one_dataset = tf.data.Dataset.zip((one_anchor_dataset, one_positive_dataset, one_negative_dataset, tf.data.Dataset.from_tensor_slices(np.ones(len(one_anchor_dataset)))))\n",
    "two_dataset = tf.data.Dataset.zip((two_anchor_dataset, two_negative_dataset, two_positive_dataset, tf.data.Dataset.from_tensor_slices(np.zeros(len(two_anchor_dataset)))))\n",
    "dataset = one_dataset.concatenate(two_dataset)\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "\n",
    "train_dataset = dataset.take(round(.8 * image_count))\n",
    "validation_dataset = dataset.skip(round(.8 * image_count))\n",
    "\n",
    "X_train = train_dataset.map(lambda anchor, positive, negative, label: (anchor, positive, negative))\n",
    "X_validation = validation_dataset.map(lambda anchor, positive, negative, label: (anchor, positive, negative))\n",
    "y_train = train_dataset.map(lambda anchor, positive, negative, label: label)\n",
    "y_validation = validation_dataset.map(lambda anchor, positive, negative, label: label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "target_shape = (224, 224)\n",
    "\n",
    "base_cnn = resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)\n",
    "\n",
    "embedding = Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "    if layer.name == \"conv5_block1_out\":\n",
    "        trainable = True\n",
    "    layer.trainable = trainable\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n",
    "positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n",
    "negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(anchor_input),\n",
    "    embedding(positive_input),\n",
    "    embedding(negative_input),\n",
    ")\n",
    "\n",
    "layer = layers.Dense(2, activation=\"relu\")(tf.stack(distances, axis=1))\n",
    "layer = layers.Dense(1, activation=\"sigmoid\")(layer)\n",
    "\n",
    "model = Model(inputs=[anchor_input, positive_input, negative_input], outputs=layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'function'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/work/gallim/ML_studies/ML-course-22/task3/try_combined.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpsi/work/gallim/ML_studies/ML-course-22/task3/try_combined.ipynb#ch0000004vscode-remote?line=6'>7</a>\u001b[0m         \u001b[39myield\u001b[39;00m (anchor, positive, negative), label\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpsi/work/gallim/ML_studies/ML-course-22/task3/try_combined.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpsi/work/gallim/ML_studies/ML-course-22/task3/try_combined.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit_generator(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalidation_generator)\n",
      "File \u001b[0;32m/work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1847\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1837'>1838</a>\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1838'>1839</a>\u001b[0m \n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1839'>1840</a>\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1840'>1841</a>\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1841'>1842</a>\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1842'>1843</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1843'>1844</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1844'>1845</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1845'>1846</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1846'>1847</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1847'>1848</a>\u001b[0m     generator,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1848'>1849</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1849'>1850</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1850'>1851</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1851'>1852</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1852'>1853</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1853'>1854</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1854'>1855</a>\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1855'>1856</a>\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1856'>1857</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1857'>1858</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1858'>1859</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1859'>1860</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1860'>1861</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[0;32m/work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1050\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1043'>1044</a>\u001b[0m   val_x, val_y, val_sample_weight \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1044'>1045</a>\u001b[0m       data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1046'>1047</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), \\\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1047'>1048</a>\u001b[0m      training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(\u001b[39mself\u001b[39m):\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1048'>1049</a>\u001b[0m   \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1049'>1050</a>\u001b[0m   data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mDataHandler(\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1050'>1051</a>\u001b[0m       x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1051'>1052</a>\u001b[0m       y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1052'>1053</a>\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1053'>1054</a>\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1054'>1055</a>\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1055'>1056</a>\u001b[0m       initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1056'>1057</a>\u001b[0m       epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1057'>1058</a>\u001b[0m       shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1058'>1059</a>\u001b[0m       class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1059'>1060</a>\u001b[0m       max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1060'>1061</a>\u001b[0m       workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1061'>1062</a>\u001b[0m       use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1062'>1063</a>\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1063'>1064</a>\u001b[0m       steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1065'>1066</a>\u001b[0m   \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1066'>1067</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1099\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1095'>1096</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1096'>1097</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_value \u001b[39m=\u001b[39m steps_per_execution\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m-> <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1098'>1099</a>\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1099'>1100</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1100'>1101</a>\u001b[0m     x,\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1101'>1102</a>\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1110'>1111</a>\u001b[0m     distribution_strategy\u001b[39m=\u001b[39mds_context\u001b[39m.\u001b[39mget_strategy(),\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1111'>1112</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m   <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1113'>1114</a>\u001b[0m strategy \u001b[39m=\u001b[39m ds_context\u001b[39m.\u001b[39mget_strategy()\n",
      "File \u001b[0;32m/work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:961\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=957'>958</a>\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=958'>959</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=959'>960</a>\u001b[0m   \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=960'>961</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=961'>962</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=962'>963</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=963'>964</a>\u001b[0m           _type_name(x), _type_name(y)))\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=964'>965</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=965'>966</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=966'>967</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=967'>968</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=968'>969</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///work/gallim/anaconda3/envs/ML-projects/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=969'>970</a>\u001b[0m           adapter_cls, _type_name(x), _type_name(y)))\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'function'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "def train_generator():\n",
    "    for anchor, positive, negative, label in train_dataset:\n",
    "        yield (anchor, positive, negative), label\n",
    "\n",
    "def validation_generator():\n",
    "    for anchor, positive, negative, label in validation_dataset:\n",
    "        yield (anchor, positive, negative), label\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator, epochs=10, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 18:18:52.042783: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-29 18:18:52.043613: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294660000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[-103.67795 , -116.50618 , -123.29737 ],\n",
      "        [-103.68668 , -116.510994, -123.31396 ],\n",
      "        [-103.6582  , -116.48609 , -123.30372 ],\n",
      "        ...,\n",
      "        [-103.6502  , -116.50662 , -123.36517 ],\n",
      "        [-103.66377 , -116.52819 , -123.391754],\n",
      "        [-103.65589 , -116.5126  , -123.372955]],\n",
      "\n",
      "       [[-103.671974, -116.500206, -123.291405],\n",
      "        [-103.68593 , -116.51024 , -123.3132  ],\n",
      "        [-103.64603 , -116.473915, -123.291534],\n",
      "        ...,\n",
      "        [-103.70965 , -116.56995 , -123.432556],\n",
      "        [-103.63599 , -116.56957 , -123.42859 ],\n",
      "        [-103.5733  , -116.50439 , -123.35625 ]],\n",
      "\n",
      "       [[-103.65192 , -116.48177 , -123.26972 ],\n",
      "        [-103.65596 , -116.48125 , -123.281265],\n",
      "        [-103.62296 , -116.45085 , -123.26848 ],\n",
      "        ...,\n",
      "        [-103.6823  , -116.53818 , -123.40422 ],\n",
      "        [-103.685776, -116.58491 , -123.45448 ],\n",
      "        [-103.60079 , -116.49667 , -123.36617 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-103.143776, -116.05992 , -123.098175],\n",
      "        [-103.13883 , -116.04742 , -123.077835],\n",
      "        [-103.130424, -116.01422 , -123.040665],\n",
      "        ...,\n",
      "        [-103.1537  , -116.037766, -123.00999 ],\n",
      "        [-103.212494, -116.1349  , -123.11922 ],\n",
      "        [-103.23229 , -116.13573 , -123.13857 ]],\n",
      "\n",
      "       [[-103.108955, -116.0251  , -123.063354],\n",
      "        [-103.11306 , -116.01149 , -123.04072 ],\n",
      "        [-103.185905, -116.06297 , -123.082306],\n",
      "        ...,\n",
      "        [-103.182755, -116.07906 , -123.04611 ],\n",
      "        [-103.17004 , -116.103165, -123.07685 ],\n",
      "        [-103.17561 , -116.08812 , -123.06576 ]],\n",
      "\n",
      "       [[-103.08318 , -115.99802 , -123.03627 ],\n",
      "        [-103.08107 , -115.97442 , -123.0019  ],\n",
      "        [-103.13202 , -115.99553 , -123.01718 ],\n",
      "        ...,\n",
      "        [-103.190506, -116.08971 , -123.058975],\n",
      "        [-103.19399 , -116.13164 , -123.07653 ],\n",
      "        [-103.1409  , -116.06581 , -123.00454 ]]], dtype=float32)>, <tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[-103.79731 , -116.71182 , -123.23243 ],\n",
      "        [-103.81671 , -116.73161 , -123.25222 ],\n",
      "        [-103.781296, -116.69972 , -123.22417 ],\n",
      "        ...,\n",
      "        [-103.765564, -116.56225 , -123.192986],\n",
      "        [-103.83379 , -116.59525 , -123.215836],\n",
      "        [-103.81961 , -116.55409 , -123.16213 ]],\n",
      "\n",
      "       [[-103.78195 , -116.698845, -123.21945 ],\n",
      "        [-103.76392 , -116.68158 , -123.20219 ],\n",
      "        [-103.80811 , -116.72761 , -123.250984],\n",
      "        ...,\n",
      "        [-103.75356 , -116.54479 , -123.17112 ],\n",
      "        [-103.81495 , -116.5788  , -123.19339 ],\n",
      "        [-103.88657 , -116.62381 , -123.22634 ]],\n",
      "\n",
      "       [[-103.7468  , -116.680984, -123.18983 ],\n",
      "        [-103.760704, -116.69105 , -123.20767 ],\n",
      "        [-103.82085 , -116.75116 , -123.267845],\n",
      "        ...,\n",
      "        [-103.794014, -116.584885, -123.1994  ],\n",
      "        [-103.77858 , -116.53612 , -123.14678 ],\n",
      "        [-103.89216 , -116.62628 , -123.22715 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-103.420494, -116.303566, -123.259224],\n",
      "        [-103.517586, -116.3968  , -123.36425 ],\n",
      "        [-103.33085 , -116.208176, -123.18351 ],\n",
      "        ...,\n",
      "        [-103.70641 , -116.59736 , -123.50626 ],\n",
      "        [-103.82091 , -116.717804, -123.636536],\n",
      "        [-103.85359 , -116.75258 , -123.66544 ]],\n",
      "\n",
      "       [[-103.36808 , -116.25712 , -123.2286  ],\n",
      "        [-103.50999 , -116.38846 , -123.36538 ],\n",
      "        [-103.23917 , -116.10909 , -123.09312 ],\n",
      "        ...,\n",
      "        [-103.74244 , -116.64084 , -123.54393 ],\n",
      "        [-103.77995 , -116.672966, -123.59245 ],\n",
      "        [-103.68751 , -116.57465 , -123.50856 ]],\n",
      "\n",
      "       [[-103.31157 , -116.19903 , -123.19057 ],\n",
      "        [-103.395615, -116.274445, -123.26756 ],\n",
      "        [-103.369194, -116.23367 , -123.226395],\n",
      "        ...,\n",
      "        [-103.654785, -116.55865 , -123.45389 ],\n",
      "        [-103.65314 , -116.54019 , -123.46085 ],\n",
      "        [-103.71505 , -116.59465 , -123.53096 ]]], dtype=float32)>, <tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[-103.38073 , -116.298416, -122.73275 ],\n",
      "        [-103.3898  , -116.300385, -122.74256 ],\n",
      "        [-103.37073 , -116.27145 , -122.72656 ],\n",
      "        ...,\n",
      "        [-103.40586 , -116.31679 , -122.827255],\n",
      "        [-103.33876 , -116.23583 , -122.76423 ],\n",
      "        [-103.40816 , -116.30294 , -122.70947 ]],\n",
      "\n",
      "       [[-103.408264, -116.31607 , -122.75264 ],\n",
      "        [-103.41867 , -116.32479 , -122.76697 ],\n",
      "        [-103.41372 , -116.30891 , -122.76402 ],\n",
      "        ...,\n",
      "        [-103.35179 , -116.29403 , -122.751076],\n",
      "        [-103.4078  , -116.30315 , -122.78551 ],\n",
      "        [-103.43693 , -116.29604 , -122.683334]],\n",
      "\n",
      "       [[-103.363304, -116.258606, -122.70832 ],\n",
      "        [-103.40978 , -116.30136 , -122.74726 ],\n",
      "        [-103.41744 , -116.306946, -122.76206 ],\n",
      "        ...,\n",
      "        [-103.323875, -116.290405, -122.85334 ],\n",
      "        [-103.397995, -116.28209 , -122.846565],\n",
      "        [-103.51058 , -116.3206  , -122.73893 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-103.393036, -116.26782 , -122.72186 ],\n",
      "        [-103.42476 , -116.320816, -122.76734 ],\n",
      "        [-103.418205, -116.32103 , -122.759026],\n",
      "        ...,\n",
      "        [-103.16062 , -116.291985, -123.67002 ],\n",
      "        [-103.22671 , -116.27649 , -123.43608 ],\n",
      "        [-103.37728 , -116.21833 , -122.95944 ]],\n",
      "\n",
      "       [[-103.44669 , -116.30979 , -122.769165],\n",
      "        [-103.403336, -116.29104 , -122.74034 ],\n",
      "        [-103.411446, -116.31442 , -122.74758 ],\n",
      "        ...,\n",
      "        [-103.162346, -116.29654 , -123.66583 ],\n",
      "        [-103.24079 , -116.29227 , -123.44307 ],\n",
      "        [-103.36923 , -116.214005, -122.94325 ]],\n",
      "\n",
      "       [[-103.423645, -116.273224, -122.74177 ],\n",
      "        [-103.42059 , -116.30178 , -122.75211 ],\n",
      "        [-103.42993 , -116.33097 , -122.76414 ],\n",
      "        ...,\n",
      "        [-103.15373 , -116.2907  , -123.65001 ],\n",
      "        [-103.24053 , -116.3006  , -123.42882 ],\n",
      "        [-103.37688 , -116.22638 , -122.94286 ]]], dtype=float32)>) tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "(<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[-103.512924, -116.339355, -123.22075 ],\n",
      "        [-103.51996 , -116.35357 , -123.24626 ],\n",
      "        [-103.47675 , -116.327385, -123.240685],\n",
      "        ...,\n",
      "        [-103.38736 , -116.2777  , -123.18655 ],\n",
      "        [-103.38302 , -116.269936, -123.20906 ],\n",
      "        [-103.33978 , -116.221275, -123.20817 ]],\n",
      "\n",
      "       [[-103.52859 , -116.35503 , -123.23787 ],\n",
      "        [-103.514885, -116.3485  , -123.241196],\n",
      "        [-103.475845, -116.32648 , -123.23978 ],\n",
      "        ...,\n",
      "        [-103.40495 , -116.292366, -123.20121 ],\n",
      "        [-103.40584 , -116.28622 , -123.162254],\n",
      "        [-103.44088 , -116.311615, -123.12943 ]],\n",
      "\n",
      "       [[-103.52437 , -116.34901 , -123.236115],\n",
      "        [-103.558754, -116.39091 , -123.29044 ],\n",
      "        [-103.49332 , -116.34674 , -123.250534],\n",
      "        ...,\n",
      "        [-103.38868 , -116.264206, -123.16867 ],\n",
      "        [-103.41909 , -116.27115 , -123.154686],\n",
      "        [-103.47072 , -116.28822 , -123.11469 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-103.801636, -116.61197 , -123.44325 ],\n",
      "        [-103.784035, -116.56814 , -123.50649 ],\n",
      "        [-103.75442 , -116.557396, -123.49601 ],\n",
      "        ...,\n",
      "        [-103.61555 , -116.44093 , -123.272606],\n",
      "        [-103.5621  , -116.401375, -123.2186  ],\n",
      "        [-103.51748 , -116.39506 , -123.271736]],\n",
      "\n",
      "       [[-103.8366  , -116.64545 , -123.481255],\n",
      "        [-103.77499 , -116.55684 , -123.50046 ],\n",
      "        [-103.80531 , -116.60829 , -123.546906],\n",
      "        ...,\n",
      "        [-103.565895, -116.37928 , -123.226776],\n",
      "        [-103.56142 , -116.38466 , -123.22519 ],\n",
      "        [-103.48593 , -116.34235 , -123.24431 ]],\n",
      "\n",
      "       [[-103.80966 , -116.61418 , -123.46269 ],\n",
      "        [-103.815445, -116.59562 , -123.54655 ],\n",
      "        [-103.78248 , -116.58546 , -123.52407 ],\n",
      "        ...,\n",
      "        [-103.53209 , -116.33735 , -123.2027  ],\n",
      "        [-103.565674, -116.37535 , -123.23635 ],\n",
      "        [-103.445885, -116.275246, -123.204285]]], dtype=float32)>, <tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[-103.42661 , -116.25768 , -123.12952 ],\n",
      "        [-103.43602 , -116.29489 , -123.16659 ],\n",
      "        [-103.410164, -116.29904 , -123.174576],\n",
      "        ...,\n",
      "        [-103.46783 , -116.284676, -123.19718 ],\n",
      "        [-103.46044 , -116.261955, -123.20217 ],\n",
      "        [-103.49144 , -116.28082 , -123.20437 ]],\n",
      "\n",
      "       [[-103.405205, -116.22615 , -123.11195 ],\n",
      "        [-103.41099 , -116.25368 , -123.13556 ],\n",
      "        [-103.42652 , -116.298836, -123.182   ],\n",
      "        ...,\n",
      "        [-103.48595 , -116.30933 , -123.21675 ],\n",
      "        [-103.466805, -116.27363 , -123.20723 ],\n",
      "        [-103.46265 , -116.263794, -123.17539 ]],\n",
      "\n",
      "       [[-103.402374, -116.20806 , -123.10832 ],\n",
      "        [-103.41915 , -116.24716 , -123.1435  ],\n",
      "        [-103.444565, -116.299515, -123.19226 ],\n",
      "        ...,\n",
      "        [-103.4649  , -116.299126, -123.190735],\n",
      "        [-103.47197 , -116.29395 , -123.21057 ],\n",
      "        [-103.48485 , -116.30047 , -123.1952  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-103.66162 , -116.41975 , -123.30299 ],\n",
      "        [-103.68977 , -116.40489 , -123.25837 ],\n",
      "        [-103.614365, -116.46784 , -123.27244 ],\n",
      "        ...,\n",
      "        [-103.5658  , -116.41846 , -123.29153 ],\n",
      "        [-103.627075, -116.40521 , -123.281334],\n",
      "        [-103.56768 , -116.440384, -123.284515]],\n",
      "\n",
      "       [[-103.682976, -116.43824 , -123.328926],\n",
      "        [-103.73082 , -116.44492 , -123.30503 ],\n",
      "        [-103.588326, -116.44009 , -123.25178 ],\n",
      "        ...,\n",
      "        [-103.56775 , -116.421104, -123.28463 ],\n",
      "        [-103.640945, -116.41759 , -123.28394 ],\n",
      "        [-103.590096, -116.459   , -123.29327 ]],\n",
      "\n",
      "       [[-103.699425, -116.45203 , -123.351746],\n",
      "        [-103.73292 , -116.44253 , -123.31473 ],\n",
      "        [-103.601685, -116.44806 , -123.27197 ],\n",
      "        ...,\n",
      "        [-103.60041 , -116.44837 , -123.30037 ],\n",
      "        [-103.65668 , -116.43202 , -123.28065 ],\n",
      "        [-103.58594 , -116.45498 , -123.26468 ]]], dtype=float32)>, <tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[-103.93778 , -116.62097 , -123.17659 ],\n",
      "        [-103.91097 , -116.60841 , -123.16212 ],\n",
      "        [-103.79773 , -116.52634 , -123.11305 ],\n",
      "        ...,\n",
      "        [-103.20656 , -115.98773 , -122.88088 ],\n",
      "        [-103.20512 , -115.98629 , -122.87945 ],\n",
      "        [-103.271996, -116.05317 , -122.94633 ]],\n",
      "\n",
      "       [[-103.9281  , -116.618805, -123.171906],\n",
      "        [-103.910225, -116.60813 , -123.165146],\n",
      "        [-103.8582  , -116.590324, -123.18049 ],\n",
      "        ...,\n",
      "        [-103.20341 , -115.98282 , -122.881256],\n",
      "        [-103.173134, -115.952545, -122.85098 ],\n",
      "        [-103.29315 , -116.07257 , -122.97101 ]],\n",
      "\n",
      "       [[-103.91487 , -116.59565 , -123.152084],\n",
      "        [-103.83265 , -116.52553 , -123.0879  ],\n",
      "        [-103.8759  , -116.61469 , -123.21332 ],\n",
      "        ...,\n",
      "        [-103.26025 , -116.04336 , -122.94828 ],\n",
      "        [-103.180275, -115.96339 , -122.86831 ],\n",
      "        [-103.27259 , -116.0557  , -122.960625]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-103.52174 , -116.23924 , -123.114   ],\n",
      "        [-103.6432  , -116.35553 , -123.23622 ],\n",
      "        [-103.67146 , -116.401794, -123.26453 ],\n",
      "        ...,\n",
      "        [-103.8051  , -116.53105 , -123.48559 ],\n",
      "        [-103.68105 , -116.42431 , -123.3634  ],\n",
      "        [-103.72982 , -116.49347 , -123.42168 ]],\n",
      "\n",
      "       [[-103.66141 , -116.37011 , -123.21401 ],\n",
      "        [-103.62848 , -116.345955, -123.20132 ],\n",
      "        [-103.63509 , -116.41468 , -123.19884 ],\n",
      "        ...,\n",
      "        [-103.75114 , -116.501724, -123.45918 ],\n",
      "        [-103.68139 , -116.4373  , -123.344734],\n",
      "        [-103.76655 , -116.518234, -123.40575 ]],\n",
      "\n",
      "       [[-103.67677 , -116.385475, -123.22938 ],\n",
      "        [-103.631905, -116.34939 , -123.20474 ],\n",
      "        [-103.62515 , -116.40474 , -123.18889 ],\n",
      "        ...,\n",
      "        [-103.78781 , -116.5384  , -123.49586 ],\n",
      "        [-103.78168 , -116.5376  , -123.44502 ],\n",
      "        [-103.79641 , -116.54809 , -123.4356  ]]], dtype=float32)>) tf.Tensor(1.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for i, e in zip(X_train, y_train):\n",
    "    print(i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4101d65f246ca3c6545fd876c414d4a4b9c372f5e6e13942927864f36a2ffe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML-projects')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
